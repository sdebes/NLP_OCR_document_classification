{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document identification with Optical Character Recognition (OCR) and Natural Language Processing (NLP)\n",
    "\n",
    "Step-by-Step Rundown\n",
    "\n",
    "    Input Handling: Accept images or PDFs as input.\n",
    "    Convert PDF to Images (if needed): Convert PDF pages to images since OCR typically works on image data.\n",
    "    Apply OCR to Extract Text: Use an OCR library to extract text from each image.\n",
    "    Pre-process the Extracted Text: Clean and prepare the text for analysis. This may involve removing noise, special characters, and stopwords.\n",
    "    NLP to Classify Document Type: Use NLP techniques such as keyword extraction, text classification, or topic modeling to determine the type of document.\n",
    "    Output the Results: Display or store the results, indicating the document type.\n",
    "\n",
    "Libraries and Tools\n",
    "    PDF to Image Conversion: Use PyMuPDF to convert PDF pages to images.\n",
    "    OCR: Use Keras-OCR to extract text from images.\n",
    "    Text Pre-processing: Use standard NLP libraries to clean and process the text data.\n",
    "    NLP: Use spacy for natural language processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import keras_ocr\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "invoice_path = \"Q:\\Code\\document_data\\sample-invoice.pdf\"\n",
    "resume_path  = \"Q:\\Code\\document_data\\cv_1.pdf\"\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\simon\\.keras-ocr\\craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From c:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: resize_bilinear (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.image.resize(...method=ResizeMethod.BILINEAR...)` instead.\n",
      "Looking for C:\\Users\\simon\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "# Initialize Keras-OCR pipeline and spaCy model\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Load NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pdf to image\n",
    "\n",
    "you could just work with the pdf as is, but using OCR, the model is more robust as it can also handle pdfs where the text is not defined (e.g. scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert PDF to images using PyMuPDF\n",
    "def pdf_to_images(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    images = []\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        # Get the page\n",
    "        page = doc.load_page(page_num)\n",
    "        # Render page to a pixmap\n",
    "        pix = page.get_pixmap()\n",
    "        # Convert pixmap to PIL Image\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        images.append(img)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the text from the images using keras OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from images using Keras-OCR\n",
    "def extract_text_from_image(image):\n",
    "    # Convert PIL image to numpy array\n",
    "    image_array = np.array(image)\n",
    "    # Run OCR on the image using Keras-OCR pipeline\n",
    "    prediction_groups = pipeline.recognize([image_array])\n",
    "    # Join all the recognized text from the predictions\n",
    "    extracted_text = ' '.join([text for text, box in prediction_groups[0]])\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the text to be fed into the NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercase and remove punctuation\n",
    "    text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify the document using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify document type\n",
    "def classify_document(text):\n",
    "    # Example: Simple keyword-based classification\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Check for certain keywords or entities\n",
    "    if any(token.text in ['invoice', 'bill'] for token in doc):\n",
    "        return 'Invoice'\n",
    "    elif any(token.text in ['resume', 'curriculum vitae'] for token in doc):\n",
    "        return 'Resume'\n",
    "    elif any(token.text in ['report', 'analysis'] for token in doc):\n",
    "        return 'Report'\n",
    "    else:\n",
    "        return 'Unknown'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the main function to run all previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main Function\n",
    "def main(pdf_path):\n",
    "    # Step 1: Convert PDF to images\n",
    "    images = pdf_to_images(pdf_path)\n",
    "\n",
    "    # Step 2: Extract text from images\n",
    "    extracted_text = \"\"\n",
    "    for image in images:\n",
    "        extracted_text += extract_text_from_image(image) + \"\\n\"\n",
    "\n",
    "    # Step 3: Pre-process extracted text\n",
    "    preprocessed_text = preprocess_text(extracted_text)\n",
    "\n",
    "    # Step 4: Classify document type\n",
    "    document_type = classify_document(preprocessed_text)\n",
    "\n",
    "    print(f\"\\nExtracted Text: \\n{extracted_text[:500]}...\")  # Print first 500 characters of the text\n",
    "    print('\\n-----------------------------------')\n",
    "    print(f\"Document Type: {document_type}\")\n",
    "    print('-----------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the function with an invoice pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "8/8 [==============================] - 15s 2s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "3/3 [==============================] - 5s 2s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "3/3 [==============================] - 4s 1s/step\n",
      "\n",
      "Extracted Text: \n",
      "cpb cpb software germany gmbh irucn ojopr oreog m olofon le sit fjus o ocpo geman onere con ee ollnes row cow cpe sofnere greh bnuch csber mtonese van gamany m s muslerkunde ag mr john doe 25 musterstr 12345 musterstadt slelanie nae sller phone sag coti stoco invoice wmaccess internet vat de1sgito66 no invoice no customer no invoice period date 2315 o1 02 2024 29 02 2024 maz 024 123100401 amount description total serice quantity amount without vat oo sasic ce dnvicr 190 10 o0 baee orioral ooo ee...\n",
      "\n",
      "-----------------------------------\n",
      "Document Type: Invoice\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Provide the path to your PDF file\n",
    "    pdf_path = invoice_path\n",
    "    main(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the function with a resume pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n",
      "6/6 [==============================] - 11s 2s/step\n",
      "\n",
      "Extracted Text: \n",
      "functional resume sample we smith john 2002 way font collins co 8025 front range iwsmithacolostate edu career summary four in childhood diverse background of experience early development with in the years care c children special needs and adults care experience adult 1s0 adult clients determined work placement for special needs maintained client databases and records coordinated client health basis with local professionals monthly contact care on d 25 volunteer managed workers childcare experien...\n",
      "\n",
      "-----------------------------------\n",
      "Document Type: Resume\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Provide the path to your PDF file\n",
    "    pdf_path = resume_path\n",
    "    main(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model correctly classified the two documents as an invoice and a resume, respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
